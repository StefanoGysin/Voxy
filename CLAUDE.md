# VOXY Agents - Sistema Multi-Agente

Sistema multi-agente inteligente desenvolvido em Python com OpenAI Agents SDK v0.3.3. Implementa orquestraÃ§Ã£o inteligente com VOXY coordenando subagentes especializados + Vision Agent GPT-5 integrado, apresentado atravÃ©s de uma interface **VOXY Web OS** completa.

> âš ï¸ **OpenAI Agents SDK v0.4.2 disponÃ­vel**: Requer migraÃ§Ã£o (breaking changes). Ver [.safe-zone/migration-plan.md] para detalhes.

> ğŸ“š Para histÃ³rico detalhado de implementaÃ§Ãµes e features, consulte [@HISTORY.md](./HISTORY.md)

## ğŸ¯ Status: 100% OPERACIONAL

- **5 Subagentes SDK**: Translator, Corrector, Weather, Calculator, Vision (LiteLLM - 400+ modelos configurÃ¡veis)
- **Vision Agent**: AnÃ¡lise multimodal com OpenAI Agents SDK + LiteLLM Multi-Provider
- **Token Usage Tracking**: Sistema centralizado de rastreamento de tokens + cost estimation (100% coverage)
- **Image Management System**: Sistema completo de gerenciamento de imagens integrado ao Web OS
- **VOXY Web OS**: Interface desktop completa com 13 wallpapers dinÃ¢micos
- **Professional Drag & Drop**: Smart swapping, collision detection, grid responsivo (6 breakpoints)
- **VOXY Orchestrator**: OpenAI Agents SDK + LiteLLM Multi-Provider (400+ modelos configurÃ¡veis via .env)
- **Remember Me System**: Auto-login e persistÃªncia de credenciais (100% funcional)
- **Stack Completa**: FastAPI + Next.js 15 + Supabase + Redis
- **Performance**: 7-8s anÃ¡lise multimodal, <2s operaÃ§Ãµes standard

## ğŸ—ï¸ Arquitetura

### Core Components
```
VOXY Orchestrator (OpenAI Agents SDK + LiteLLM Multi-Provider)
â”œâ”€â”€ Model Selection: 100% configurÃ¡vel via .env (ORCHESTRATOR_MODEL)
â”œâ”€â”€ Configuration: 100% via environment variables (ORCHESTRATOR_*)
â”œâ”€â”€ Architecture: Factory pattern (models_config.py + llm_factory.py)
â”œâ”€â”€ Flexibility: 400+ modelos disponÃ­veis (OpenRouter, OpenAI, Anthropic, Google)
â””â”€â”€ 5 Subagentes SDK (OpenAI Agents SDK + LiteLLM - 400+ modelos)
  â”œâ”€â”€ Translator, Corrector, Weather, Calculator (LiteLLM configurÃ¡veis)
  â””â”€â”€ Vision Agent (OpenAI Agents SDK + LiteLLM Multi-Provider)
      â”œâ”€â”€ Dual-Path: Bypass direto + DecisÃ£o VOXY
      â”œâ”€â”€ Cache: L1 memory + L2 Redis
      â”œâ”€â”€ Provider: openrouter | openai | anthropic
      â””â”€â”€ Features: Adaptive reasoning + Cost tracking
â”œâ”€â”€ Image Management System
â”‚   â”œâ”€â”€ Upload: Drag & drop + validation + progress tracking
â”‚   â”œâ”€â”€ Storage: Supabase Storage + organized paths
â”‚   â”œâ”€â”€ UI: 5 React components + responsive grid
â”‚   â””â”€â”€ Integration: VOXY Web OS icon + JWT auth
â””â”€â”€ Authentication System
  â”œâ”€â”€ Remember Me: Auto-login + Credential persistence
  â”œâ”€â”€ JWT Tokens: 24h expiration + JTI tracking
  â”œâ”€â”€ Redis Blacklisting: Token invalidation system
  â””â”€â”€ Security: Smart logout + Error handling
```

### Vision Agent Dual-Path
- **PATH 1 (Bypass)**: `image_url + keywords` â†’ Vision Agent direto (7-8s)
- **PATH 2 (VOXY)**: URL no texto â†’ VOXY decide â†’ @function_tool (9-10s)

## ğŸ“‹ Stack TecnolÃ³gico

**Backend**: Python 3.12+ (min 3.12.3), Poetry 2.1.4, FastAPI, Uvicorn
**AI**: OpenAI Agents SDK 0.3.3, LiteLLM 1.75.7+ Multi-Provider (400+ modelos configurÃ¡veis via .env)
**Database**: Supabase (PostgreSQL + Auth + Storage)
**Cache**: Redis 5.0+ (Token blacklisting + Vision cache)
**Frontend**: Next.js 15.4.6, TypeScript, TailwindCSS, Radix UI
**Web OS**: EnhancedOSDashboard, WallpaperSystem, Professional Drag & Drop
**Security**: JWT + JTI (24-hour expiration), Remember Me, CORS, RLS policies

## ğŸ“ Estrutura do Projeto

```
voxy/
â”œâ”€â”€ CLAUDE.md                  # Este arquivo (instruÃ§Ãµes para Claude)
â”œâ”€â”€ HISTORY.md                 # HistÃ³rico detalhado de implementaÃ§Ãµes
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/voxy_agents/
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ subagents/      # 4 agentes + vision_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ voxy_orchestrator.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_token_manager.py # JWT + Redis blacklisting
â”‚   â”‚   â”‚   â”œâ”€â”€ cache/          # Redis + Vision cache
â”‚   â”‚   â”‚   â””â”€â”€ optimization/   # Adaptive reasoning
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py       # Modelos compartilhados (DRY principle)
â”‚   â”‚   â”‚   â””â”€â”€ routes/         # 6 mÃ³dulos API + auth
â”‚   â”‚   â”œâ”€â”€ config/             # models_config.py (LiteLLM)
â”‚   â”‚   â””â”€â”€ utils/              # llm_factory.py + usage_tracker.py + test_subagents.py
â”‚   â”œâ”€â”€ tests/                  # 213+ testes (89% coverage)
â”‚   â”œâ”€â”€ scripts/                # test_agent.py (CLI testing)
â”‚   â””â”€â”€ pyproject.toml          # Poetry config
â””â”€â”€ frontend/
  â”œâ”€â”€ src/components/
  â”‚   â”œâ”€â”€ os/                 # VOXY Web OS Components
  â”‚   â”‚   â”œâ”€â”€ EnhancedOSDashboard.tsx
  â”‚   â”‚   â”œâ”€â”€ WallpaperSystem.tsx (13 presets)
  â”‚   â”‚   â”œâ”€â”€ AppIcon.tsx (draggable)
  â”‚   â”‚   â”œâ”€â”€ DateTimeWidget.tsx
  â”‚   â”‚   â”œâ”€â”€ DragDropProvider.tsx (smart collision)
  â”‚   â”‚   â””â”€â”€ hooks/          # useResponsiveGrid, useProtectedAreas
  â”‚   â”œâ”€â”€ images/             # Image Management System (5 components)
  â”‚   â”œâ”€â”€ ui/                 # Radix UI components
  â”‚   â”œâ”€â”€ auth/               # Enhanced with Remember Me
  â”‚   â””â”€â”€ chat/               # Integrated VOXY Chat
  â”œâ”€â”€ lib/
  â”‚   â”œâ”€â”€ api/images.ts       # Image Management API client
  â”‚   â””â”€â”€ store/              # os-store, auth-store, session-store
  â””â”€â”€ src/app/
      â”œâ”€â”€ page.tsx            # VOXY Web OS main interface
      â”œâ”€â”€ chat/page.tsx       # Chat application
      â””â”€â”€ images/page.tsx     # Image Management page
```

## ğŸ“ Estrutura de DocumentaÃ§Ã£o

**IMPORTANTE - OrganizaÃ§Ã£o de DocumentaÃ§Ã£o**:

- **`.safe-zone/`**: Ãrea de desenvolvimento/rascunho (NÃƒO commitada ao git)
  - Use livremente para notas tÃ©cnicas, planos de implementaÃ§Ã£o, findings de auditoria
  - ConteÃºdo desta pasta NÃƒO entra no repositÃ³rio
  - Ideal para documentaÃ§Ã£o tÃ©cnica temporÃ¡ria e trabalho em progresso

- **`docs/`**: DocumentaÃ§Ã£o oficial do projeto (commitada ao git)
  - **REQUER AUTORIZAÃ‡ÃƒO** do usuÃ¡rio antes de criar/modificar arquivos aqui
  - ContÃ©m documentaÃ§Ã£o pÃºblica e permanente do projeto
  - Apenas documentaÃ§Ã£o finalizada e aprovada

**Regra**: Claude pode criar documentaÃ§Ã£o livremente em `.safe-zone/` mas NUNCA em `docs/` sem autorizaÃ§Ã£o explÃ­cita.

## ğŸ”§ Consultando ConfiguraÃ§Ã£o de Modelos Atual

**IMPORTANTE**: A documentaÃ§Ã£o usa modelos como **exemplos** (defaults configurados em `.env.example`).
Para saber qual modelo estÃ¡ **realmente sendo usado** no ambiente atual:

1. **Verificar arquivo .env**:
   ```bash
   grep "ORCHESTRATOR_MODEL\|CALCULATOR_MODEL\|VISION_MODEL" backend/.env
   ```

2. **Consultar quando necessÃ¡rio**: Antes de assumir qual modelo estÃ¡ ativo, sempre consulte o `.env`
   ou pergunte ao usuÃ¡rio sobre a configuraÃ§Ã£o atual.

3. **Flexibilidade**: Qualquer referÃªncia a "Claude Sonnet 4.5", "GPT-4o", etc. na documentaÃ§Ã£o
   refere-se aos **defaults sugeridos**, nÃ£o a requisitos fixos.

## ğŸ§ª Testing & Quality

**Coverage**:
- Vision Agent: 74% (15 testes unitÃ¡rios - SDK pattern)
- Remember Me System: 100% funcional (integraÃ§Ã£o completa)
- Auth System: JWT + Redis blacklisting operacional
- Core Modules: 85%+ coverage
- Total Tests: 213+ testes passando

**Performance Metrics**:
```
- Mensagem simples: ~1.5s
- Vision anÃ¡lise (cache miss): 7-8s
- Vision cache hit: <1s
- Remember Me auto-login: <2s
- Upload imagem: <3s
- WebSocket latency: <100ms
- Drag & Drop: <50ms snap time
- Grid adaptaÃ§Ã£o: <200ms breakpoint change
```

## âš™ï¸ ConfiguraÃ§Ã£o Desenvolvimento

### Backend Setup
```bash
cd /mnt/d/Projeto-Voxy/voxy/backend
poetry install
poetry run uvicorn src.voxy_agents.api.fastapi_server:app --reload
```

### Frontend Setup
```bash
cd /mnt/d/Projeto-Voxy/voxy/frontend
npm install
npm run dev
```

### Testing
```bash
# Backend tests
poetry run pytest --cov=src --cov-report=html

# Isolated subagent testing (18x mais rÃ¡pido)
poetry run python scripts/test_agent.py translator --text "Hello" --target-language "pt-BR"
poetry run python scripts/test_agent.py --interactive
```

## ğŸš€ URLs de Teste

- **VOXY Web OS**: http://localhost:3000/ (usuÃ¡rios autenticados)
- **VOXY Chat**: http://localhost:3000/chat (integrado ao OS)
- **Image Manager**: http://localhost:3000/images (gerenciamento de imagens)
- **Authentication**: http://localhost:3000/auth/login
- **Remember Me Debug**: http://localhost:3000/test-remember-me

## ğŸ” ConfiguraÃ§Ãµes de Ambiente

**IMPORTANTE - Sistema Model-Agnostic**:

O VOXY Agents Ã© **100% configurÃ¡vel via variÃ¡veis de ambiente**. NÃ£o hÃ¡ modelos hardcoded no cÃ³digo.
Todos os modelos (VOXY Orchestrator + 5 Subagentes) sÃ£o configurados atravÃ©s do arquivo `.env`.

**Para configurar seu ambiente**:

1. **Copie o template**:
   ```bash
   cp backend/.env.example backend/.env
   ```

2. **Edite `backend/.env`** com suas credenciais e preferÃªncias de modelos

3. **Consulte `.env.example`** para ver:
   - VariÃ¡veis obrigatÃ³rias vs. opcionais
   - Exemplos de configuraÃ§Ã£o (nÃ£o sÃ£o requisitos!)
   - ComentÃ¡rios sobre cada parÃ¢metro
   - SugestÃµes de modelos por caso de uso

**Categorias de ConfiguraÃ§Ã£o**:

```bash
# 1. API Keys & Authentication
OPENROUTER_API_KEY=          # Para 400+ modelos via OpenRouter
OPENAI_API_KEY=              # Para modelos OpenAI diretos
ANTHROPIC_API_KEY=           # Para Claude direto
GOOGLE_API_KEY=              # Para Gemini direto

# 2. Database & Cache
SUPABASE_URL=
SUPABASE_ANON_KEY=
SUPABASE_SERVICE_KEY=
SUPABASE_JWT_SECRET=
REDIS_URL=

# 3. VOXY Orchestrator
ORCHESTRATOR_PROVIDER=       # openrouter | openai | anthropic | google
ORCHESTRATOR_MODEL=          # Qualquer modelo suportado pelo provider
ORCHESTRATOR_MAX_TOKENS=
ORCHESTRATOR_TEMPERATURE=
ORCHESTRATOR_REASONING_EFFORT=

# 4. Subagentes (Calculator, Corrector, Translator, Weather, Vision)
# Cada um configurÃ¡vel independentemente:
<AGENT>_PROVIDER=            # openrouter | openai | anthropic | google
<AGENT>_MODEL=               # Qualquer modelo do provider
<AGENT>_MAX_TOKENS=
<AGENT>_TEMPERATURE=

# 5. External APIs
OPENWEATHER_API_KEY=         # Para Weather Agent
```

**âš ï¸ Nenhuma ReferÃªncia Hardcoded**:
- âŒ CÃ³digo NÃƒO contÃ©m modelos especÃ­ficos
- âœ… Tudo vem do `.env`
- âœ… Trocar modelos = apenas editar `.env` (zero mudanÃ§as de cÃ³digo)
- âœ… Suporta 400+ modelos via LiteLLM Multi-Provider

**Consulte sempre**:
- `backend/.env.example` - Template oficial com exemplos comentados
- [SeÃ§Ã£o "Consultando ConfiguraÃ§Ã£o de Modelos Atual"](#ğŸ”§-consultando-configuraÃ§Ã£o-de-modelos-atual) acima

## ğŸ“‹ Comandos Essenciais

**Backend**:
```bash
# Rodar servidor
poetry run uvicorn src.voxy_agents.api.fastapi_server:app --reload

# Testes
poetry run pytest --cov=src --cov-report=html

# Testar subagente isolado
poetry run python scripts/test_agent.py <agent_name> [args]

# Quality Checks (executam automaticamente via pre-commit hooks)
poetry run ruff check .
poetry run black --check src/ tests/
poetry run mypy src/

# Pre-commit (validaÃ§Ã£o completa antes de commit)
poetry run pre-commit run --all-files  # Ver docs/PRE_COMMIT_GUIDE.md
```

**Frontend**:
```bash
# Development
npm run dev

# Build
npm run build

# Typecheck
npm run typecheck

# Lint
npm run lint
```

## ğŸ›ï¸ Modelos Centralizados (DRY Principle)

**Arquivo**: `backend/src/voxy_agents/api/models.py`

5 modelos compartilhados entre rotas:
- `MessageResponse` - Mensagem de chat individual
- `MessagesListResponse` - Lista paginada de mensagens
- `SearchRequest` - Busca avanÃ§ada unificada
- `SearchResultItem` - Item de resultado de busca
- `SearchResponse` - Resposta de busca com metadata

**BenefÃ­cios**: ManutenÃ§Ã£o simplificada, Type Safety, PrevenÃ§Ã£o de bugs, EvoluÃ§Ã£o segura

## ğŸ”§ LiteLLM Migration Pattern

**PadrÃ£o implementado** (Calculator Agent):
1. ConfiguraÃ§Ã£o centralizada em `config/models_config.py`
2. Factory pattern em `utils/llm_factory.py`
3. Subagent refatorado para usar LiteLLM Model

**Como migrar outro subagente**:
1. Adicionar funÃ§Ã£o `load_<subagent>_config()` em `models_config.py`
2. Refatorar subagent para importar config + factory
3. Adicionar env vars em `.env.example`
4. Atualizar testes para mockar `load_config` e `create_litellm_model`

## ğŸ§ª Sistema de Testes Isolados

**Bypass do VOXY Orchestrator** para debug rÃ¡pido:
- Debug 18x mais rÃ¡pido: 37s â†’ 2s (standard agents)
- 4 componentes: MÃ³dulo principal, Testes unitÃ¡rios, CLI script, HTTP endpoints
- 6 agentes testÃ¡veis: 5 subagentes + VOXY Orchestrator
- 5 endpoints HTTP: `/api/test/subagent`, `/api/test/agents`, etc.
- CLI rico: ANSI colors, interactive mode, benchmark, export JSON/CSV

**Exemplo CLI (Subagentes)**:
```bash
# Testar tradutor
poetry run python scripts/test_agent.py translator \
--text "Hello world" \
--target-language "pt-BR"

# Testar Vision Agent
poetry run python scripts/test_agent.py vision \
--image-url "https://example.com/image.jpg" \
--query "O que vocÃª vÃª?"
```

**Exemplo CLI (VOXY Orchestrator)**:
```bash
# Teste simples
poetry run python scripts/test_agent.py voxy \
--message "Traduza 'Hello world' para portuguÃªs"

# Com imagem (anÃ¡lise multimodal via Vision Agent)
poetry run python scripts/test_agent.py voxy \
--message "Qual emoji Ã© este?" \
--image-url "https://example.com/emoji.png"

# Benchmark mode
poetry run python scripts/test_agent.py voxy \
--message "Quanto Ã© 2+2?" \
--benchmark --iterations 5

# Modo interativo
poetry run python scripts/test_agent.py --interactive
# Digite: voxy
# message: Traduza "Hello" para francÃªs
```

## ğŸ“Š API Endpoints Principais

**Auth**:
- `POST /api/auth/login` - Login + Remember Me
- `POST /api/auth/logout` - Logout + Token blacklisting
- `GET /api/auth/me` - User info
- `GET /api/auth/validate` - Token validation

**Chat**:
- `POST /api/chat` - Send message (VOXY Orchestrator)
- `GET /api/sessions` - List sessions
- `POST /api/sessions` - Create session
- `GET /api/sessions/{id}/messages` - Get messages

**Images**:
- `POST /api/images/upload` - Upload with metadata
- `GET /api/images/` - List with filters
- `PUT /api/images/{id}` - Update metadata
- `DELETE /api/images/{id}` - Delete image

**Testing**:
- `POST /api/test/subagent` - Test isolated subagent or VOXY Orchestrator
- `GET /api/test/agents` - List available agents (5 subagentes + voxy)
- `POST /api/test/batch` - Batch testing (up to 10)
- `GET /api/test/health` - Health check do sistema de testes

## ğŸ¯ Features Principais

**Orchestrator LiteLLM**: VOXY totalmente configurÃ¡vel (400+ modelos via .env)
**Multi-Agent System**: 5 subagentes (OpenAI Agents SDK + LiteLLM) + Flow Corrections
**Token Usage Tracking**: Rastreamento centralizado de tokens + cost estimation via LiteLLM (100% tested)
**Image Management**: Upload, grid responsivo, modal, busca, metadata editing
**VOXY Web OS**: Interface desktop com 13 wallpapers + Grid responsivo (6 breakpoints)
**Professional Drag & Drop**: Smart swapping + collision detection
**Remember Me**: Auto-login + persistÃªncia de credenciais (7 dias)
**JWT Advanced**: 24h tokens + JTI tracking + Redis blacklisting
**Isolated Testing**: Sistema completo para testar subagentes individualmente
**API DRY**: Modelos centralizados em `api/models.py`
**LiteLLM Support**: 400+ modelos configurÃ¡veis via `.env` (Orchestrator + 5 Subagentes)

## ğŸ“ Code Style & Workflow

**Python**:
- Use Poetry para gerenciamento de dependÃªncias
- Siga PEP 8 (enforced by Ruff)
- Type hints obrigatÃ³rios (enforced by mypy)
- Async/await para operaÃ§Ãµes IO-bound
- Pydantic models para validaÃ§Ã£o de dados
- DRY principle: Centralize modelos compartilhados em `api/models.py`

**TypeScript/React**:
- Use ES modules (import/export), nÃ£o CommonJS (require)
- Destructure imports quando possÃ­vel: `import { foo } from 'bar'`
- TypeScript strict mode enabled
- Radix UI para componentes de UI
- Zustand para state management
- TailwindCSS para styling
- Next.js 15 App Router

**Workflow**:
- **Pre-commit hooks instalados**: ValidaÃ§Ã£o automÃ¡tica antes de cada commit (ver [`docs/PRE_COMMIT_GUIDE.md`](./docs/PRE_COMMIT_GUIDE.md))
- Sempre execute typecheck apÃ³s mudanÃ§as: `npm run typecheck` (frontend), `poetry run mypy src/` (backend)
- Rode testes antes de commits: `poetry run pytest --cov=src`
- Use sistema de testes isolados para debug rÃ¡pido de subagentes
- Commits devem passar pelo fluxo: **pre-commit hooks** â†’ lint â†’ typecheck â†’ tests â†’ commit
- Para features visuais, teste em todos os 6 breakpoints responsivos

## ğŸ“š Documentation-First Approach (CRÃTICO!)

**LiÃ§Ã£o Aprendida**: Sempre consulte a documentaÃ§Ã£o oficial ANTES de implementar qualquer feature.

### âš ï¸ Regra de Ouro: Documente ANTES de Codificar

**SEMPRE use Context7 MCP para consultar documentaÃ§Ãµes** antes de implementar:

1. **ANTES de criar qualquer cÃ³digo**, verifique se a funcionalidade jÃ¡ existe na biblioteca
2. **ANTES de implementar uma feature**, consulte docs oficiais via Context7
3. **ANTES de corrigir um bug**, confirme o comportamento esperado na documentaÃ§Ã£o

### ğŸ” Como Usar Context7 Corretamente

**Exemplo Real - Token Usage Tracking (2025-10-25)**:

âŒ **ERRADO** (o que NÃƒO fazer):
```python
# Tentamos implementar token tracking manualmente
if hasattr(result, 'usage') and result.usage:  # âŒ Caminho ERRADO
    tokens = result.usage.total_tokens
```

âœ… **CORRETO** (consultar documentaÃ§Ã£o primeiro):
```bash
# 1. Resolver library ID
mcp__context7__resolve-library-id("openai agents sdk")

# 2. Buscar documentaÃ§Ã£o sobre token usage
mcp__context7__get-library-docs(
    context7CompatibleLibraryID="/openai/openai-agents-python",
    topic="token usage RunResult response tracking"
)

# Descoberta: OpenAI Agents SDK usa result.context_wrapper.usage
if hasattr(result, 'context_wrapper') and result.context_wrapper.usage:  # âœ… CORRETO
    tokens = result.context_wrapper.usage.total_tokens
```

### ğŸ“– Bibliotecas Principais para Consultar

**Sempre consulte via Context7 antes de usar**:

| Biblioteca | Library ID | Quando Consultar |
|------------|-----------|------------------|
| **LiteLLM** | `/berriai/litellm` | Token tracking, cost calculation, model usage |
| **OpenAI Agents SDK** | `/openai/openai-agents-python` | Agent patterns, Runner API, sessions, usage |
| **Next.js** | Context7 search | Routing, data fetching, app directory |
| **Supabase** | Context7 search | Auth, database, storage, realtime |
| **Radix UI** | Context7 search | Component APIs, accessibility |

### ğŸ¯ Workflow Recomendado

```
1. ğŸ“‹ User pede feature/fix
2. ğŸ” PRIMEIRO: Consultar Context7 (library docs)
3. ğŸ“– Ler padrÃµes oficiais e best practices
4. ğŸ’¡ Verificar se feature JÃ existe na lib
5. âŒ¨ï¸  ENTÃƒO: Implementar usando padrÃµes corretos
6. âœ… Testar e validar
```

### âš¡ BenefÃ­cios Comprovados

**Caso Real**: Token Usage Tracking Implementation

| Abordagem | Tempo | Resultado |
|-----------|-------|-----------|
| âŒ **Sem consultar docs** | 2h tentando `result.usage` | FALHA - caminho incorreto |
| âœ… **Com Context7 docs** | 30min | SUCESSO - `context_wrapper.usage` + testes 100% |

**Economia**: **75% menos tempo** + **soluÃ§Ã£o correta** desde o inÃ­cio

### ğŸš¨ Sinais de Alerta

**PARE e consulte documentaÃ§Ã£o quando**:
- â“ "Como faÃ§o X com biblioteca Y?"
- ğŸ¤” "Esse atributo nÃ£o existe..."
- ğŸ˜• "Por que nÃ£o estÃ¡ funcionando?"
- ğŸ” "JÃ¡ tentei 3 formas diferentes..."

**Resposta**: ğŸ“š **Abra Context7 e consulte a documentaÃ§Ã£o oficial!**

### ğŸ’¡ Exemplo PrÃ¡tico de Consulta

**Problema**: Implementar streaming com LiteLLM

**Workflow Correto**:
```typescript
// 1. Resolver library ID
const libraryId = await resolveLibraryId("litellm");

// 2. Consultar docs sobre streaming
const docs = await getLibraryDocs({
    libraryId: "/berriai/litellm",
    topic: "streaming responses token usage",
    tokens: 6000
});

// 3. Implementar seguindo padrÃ£o oficial descoberto
const response = completion({
    model: "gpt-4",
    messages: [...],
    stream: true,
    stream_options: { include_usage: true }  // âœ… Da documentaÃ§Ã£o!
});
```

### âœ… Checklist Antes de Implementar

- [ ] Consultei Context7 para verificar se a funcionalidade existe?
- [ ] Li os exemplos oficiais da biblioteca?
- [ ] Verifiquei se minha abordagem estÃ¡ alinhada com os padrÃµes da lib?
- [ ] Confirmei que nÃ£o estou "reinventando a roda"?

**Se algum item for "NÃƒO"**: ğŸ›‘ **PARE e consulte a documentaÃ§Ã£o primeiro!**

---

**Resumo**: Context7 Ã© sua **primeira ferramenta**, nÃ£o a Ãºltima. Use-o **proativamente** para economizar tempo e implementar soluÃ§Ãµes corretas desde o inÃ­cio.

## ğŸ”„ Summary Instructions

Quando usar auto-compact, foque em:
- Test output e cÃ³digo alterado
- Erros e warnings relevantes
- DecisÃµes arquiteturais importantes
- MudanÃ§as em modelos de dados
- Performance metrics crÃ­ticos

---

**Sistema multi-agente enterprise-ready com VOXY Orchestrator (LiteLLM Multi-Provider) + 5 Subagentes SDK (OpenAI Agents + LiteLLM configurÃ¡veis) + Token Usage Tracking Centralizado + VOXY Web OS + Image Management System + API Architecture DRY-compliant + Pre-commit Quality Hooks + Documentation-First Approach completamente implementado e 100% operacional.**

*Ãšltima atualizaÃ§Ã£o: 2025-10-25 - Token Usage Tracking System + Documentation-First Approach via Context7*
