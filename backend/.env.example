# VOXY Agents Environment Variables

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# OpenRouter API Configuration (for alternative models)
OPENROUTER_API_KEY=sk-or-your_openrouter_api_key_here
OR_SITE_URL=https://voxy.ai                    # [OPTIONAL] Your site URL for OpenRouter analytics
OR_APP_NAME=VOXY Agents                        # [OPTIONAL] Your app name for OpenRouter analytics

# Model Configuration (LEGACY - deprecated, use ORCHESTRATOR_* below)
VOXY_ORCHESTRATOR_MODEL=gpt-4o

# ============================================
# VOXY ORCHESTRATOR CONFIGURATION (LiteLLM)
# ============================================
# Main orchestrator uses OpenAI Agents SDK + LiteLLM Multi-Provider
# Supports 400+ models via configurable provider

ORCHESTRATOR_PROVIDER=openrouter                      # openrouter | openai | anthropic
ORCHESTRATOR_MODEL=anthropic/claude-sonnet-4.5       # 2025 Premium: Advanced reasoning ($3/$15 per 1M)
# Alternatives:
# - openai/gpt-4o (Balanced: $2.50/$10)
# - google/gemini-2.5-pro (Budget: $1.25/$10)
# - deepseek/deepseek-chat-v3.1 (Math-focused: $0.20/$0.80)
ORCHESTRATOR_MAX_TOKENS=4000
ORCHESTRATOR_TEMPERATURE=0.3                          # Moderate for reasoning
ORCHESTRATOR_REASONING_EFFORT=medium                  # minimal | low | medium | high
ORCHESTRATOR_INCLUDE_USAGE=true
ORCHESTRATOR_ENABLE_STREAMING=false                   # Future feature flag

# ============================================
# SUBAGENT MODEL CONFIGURATION (2025)
# ============================================
# All subagents support 400+ models via LiteLLM Multi-Provider Architecture
# Provider options: openrouter | openai | anthropic | google
# OpenRouter recommended for access to all models + pass-through pricing

# Calculator Subagent Configuration (via LiteLLM)
CALCULATOR_PROVIDER=openrouter                         # openrouter | openai | anthropic
CALCULATOR_MODEL=deepseek/deepseek-chat-v3.1          # 2025 Best: Math reasoning + low cost ($0.20/$0.80 per 1M)
# Alternatives:
# - anthropic/claude-sonnet-4.5 (Premium: $3/$15)
# - openai/gpt-4.1-mini (Balanced: $0.10/$0.40)
# - deepseek/deepseek-chat-v3-0324:free (FREE)
CALCULATOR_MAX_TOKENS=2000
CALCULATOR_TEMPERATURE=0.1                             # Low for precision
CALCULATOR_INCLUDE_USAGE=true

# Corrector Subagent Configuration (via LiteLLM)
CORRECTOR_PROVIDER=openrouter                          # openrouter | openai | anthropic
CORRECTOR_MODEL=google/gemini-2.5-flash-preview       # 2025 Best: PT-BR grammar + cost ($0.30/$2.50 per 1M)
# Alternatives:
# - anthropic/claude-3.7-sonnet (Premium: $3/$15)
# - google/gemini-2.0-flash-exp (FREE)
CORRECTOR_MAX_TOKENS=2000
CORRECTOR_TEMPERATURE=0.1                              # Low for consistency
CORRECTOR_INCLUDE_USAGE=true

# Translator Subagent Configuration (via LiteLLM)
TRANSLATOR_PROVIDER=openrouter                         # openrouter | openai | anthropic
TRANSLATOR_MODEL=google/gemini-2.5-pro                # 2025 Best: Multilingual quality ($1.25/$10 per 1M)
# Alternatives:
# - anthropic/claude-3.7-sonnet (Excellent: $3/$15)
# - google/gemini-2.5-flash-preview (Budget: $0.30/$2.50)
# - deepseek/deepseek-chat-v3-0324:free (FREE)
TRANSLATOR_MAX_TOKENS=2000
TRANSLATOR_TEMPERATURE=0.3                             # Moderate for creativity
TRANSLATOR_INCLUDE_USAGE=true

# Weather Subagent Configuration (via LiteLLM)
WEATHER_PROVIDER=openrouter                            # openrouter | openai | anthropic
WEATHER_MODEL=openai/gpt-4.1-nano                     # 2025 Best: Tool calling + low latency ($0.10/$0.40 per 1M)
# Alternatives:
# - google/gemini-2.5-flash-preview (Budget: $0.30/$2.50)
# - openai/gpt-4o-mini (Stable: $0.15/$0.60)
WEATHER_MAX_TOKENS=1500
WEATHER_TEMPERATURE=0.1
WEATHER_INCLUDE_USAGE=true

# ============================================
# VISION AGENT CONFIGURATION (LiteLLM)
# ============================================
# Vision Agent uses OpenAI Agents SDK + LiteLLM Multi-Provider
# Supports 400+ multimodal models via configurable provider

VISION_PROVIDER=openrouter                    # openrouter | openai | anthropic
VISION_MODEL=openai/gpt-4o                    # 2025 Best: Multimodal ($2.50/$10 per 1M)
# Alternatives:
# - anthropic/claude-3.5-sonnet (Claude Vision: $3/$15)
# - google/gemini-2.5-pro (Gemini Vision: $1.25/$10)
VISION_MAX_TOKENS=2000
VISION_TEMPERATURE=0.1
VISION_REASONING_EFFORT=medium                # minimal | low | medium | high
VISION_CACHE_TTL=600                          # Cache TTL in seconds
VISION_INCLUDE_USAGE=true

# Vision Agent Post-processing
ENABLE_VISION_POSTPROCESSING=true

# Vision Agent Rate Limiting (MANTIDO)
VISION_RATE_LIMIT_PER_MINUTE=10
VISION_RATE_LIMIT_PER_HOUR=50
VISION_MONTHLY_QUOTA=1000

# Vision Agent Cost Control (MANTIDO)
VISION_MAX_COST_PER_ANALYSIS=0.10
VISION_DAILY_BUDGET_LIMIT=50.00
VISION_MONTHLY_BUDGET_LIMIT=500.00

# Weather API (Optional)
OPENWEATHER_API_KEY=your_openweather_api_key_here

# Supabase Configuration (Optional)
SUPABASE_URL=your_supabase_url_here
SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_KEY=your_supabase_service_key_here
SUPABASE_JWT_SECRET=your_supabase_jwt_secret_here

# JWT Token Configuration
SUPABASE_JWT_EXPIRATION_HOURS=24

# System Configuration
LOG_LEVEL=INFO
ENVIRONMENT=development

# VOXY Logging Configuration
# Controls VOXY system logging level and visual output
# Options: DEBUG | INFO | WARNING | ERROR
VOXY_LOG_LEVEL=INFO              # INFO = Visual limpo (startup sem cabeçalhos), DEBUG = Rastreamento completo
VOXY_ENV=development             # development | production
VOXY_LOG_DIR=logs                # Diretório de logs
VOXY_LOG_JSON=false              # Habilitar JSON sink para ELK/Loki

# Visual Limpo em Startup:
# - VOXY_LOG_LEVEL=INFO: Logs STARTUP aparecem SEM cabeçalho (visual limpo)
# - VOXY_LOG_LEVEL=DEBUG: Logs STARTUP aparecem COM cabeçalho (rastreamento técnico)

# IMPORTANTE: Override Behavior
# O sistema usa load_dotenv(override=True) em todos os módulos de configuração.
# Isso significa que valores neste arquivo .env sempre têm PRIORIDADE sobre
# variáveis de ambiente setadas no shell (via export).
#
# Exemplo:
# - Shell: export VOXY_LOG_LEVEL=INFO
# - .env:  VOXY_LOG_LEVEL=DEBUG
# - Resultado: Sistema usa DEBUG (valor do .env sobrescreve shell)

# LiteLLM Logging Configuration
# Controls LiteLLM's native logging (prevents duplicate logs)
# Options: DEBUG | INFO | WARNING | ERROR
LITELLM_LOG=ERROR                # Recommended: ERROR (only critical issues, avoids duplication)