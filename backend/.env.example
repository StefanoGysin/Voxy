# VOXY Agents Environment Variables

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# OpenRouter API Configuration (for alternative models)
OPENROUTER_API_KEY=sk-or-your_openrouter_api_key_here
OR_SITE_URL=https://voxy.ai                    # [OPTIONAL] Your site URL for OpenRouter analytics
OR_APP_NAME=VOXY Agents                        # [OPTIONAL] Your app name for OpenRouter analytics

# Model Configuration (LEGACY - deprecated, use ORCHESTRATOR_* below)
# VOXY_ORCHESTRATOR_MODEL=gpt-4o  # ⚠️ DEPRECATED - Usar ORCHESTRATOR_MODEL (linha 21)

# ============================================
# VOXY ORCHESTRATOR CONFIGURATION (LiteLLM)
# ============================================
# Main orchestrator uses OpenAI Agents SDK + LiteLLM Multi-Provider
# Supports 400+ models via configurable provider

ORCHESTRATOR_PROVIDER=openrouter                      # openrouter | openai | anthropic
ORCHESTRATOR_MODEL=anthropic/claude-sonnet-4.5       # 2025 Premium: Advanced reasoning ($3/$15 per 1M)
# Alternatives:
# - openai/gpt-4o (Balanced: $2.50/$10)
# - google/gemini-2.5-pro (Budget: $1.25/$10)
# - deepseek/deepseek-chat-v3.1 (Math-focused: $0.20/$0.80)
ORCHESTRATOR_MAX_TOKENS=4000
ORCHESTRATOR_TEMPERATURE=0.3                          # Moderate for reasoning
ORCHESTRATOR_REASONING_EFFORT=medium                  # minimal | low | medium | high
ORCHESTRATOR_INCLUDE_USAGE=true
ORCHESTRATOR_ENABLE_STREAMING=false                   # Future feature flag

# ============================================
# SUBAGENT MODEL CONFIGURATION (2025)
# ============================================
# All subagents support 400+ models via LiteLLM Multi-Provider Architecture
# Provider options: openrouter | openai | anthropic | google
# OpenRouter recommended for access to all models + pass-through pricing

# Calculator Subagent Configuration (via LiteLLM)
CALCULATOR_PROVIDER=openrouter                         # openrouter | openai | anthropic
CALCULATOR_MODEL=deepseek/deepseek-chat-v3.1          # 2025 Best: Math reasoning + low cost ($0.20/$0.80 per 1M)
# Alternatives:
# - anthropic/claude-sonnet-4.5 (Premium: $3/$15)
# - openai/gpt-4.1-mini (Balanced: $0.10/$0.40)
# - deepseek/deepseek-chat-v3-0324:free (FREE)
CALCULATOR_MAX_TOKENS=2000
CALCULATOR_TEMPERATURE=0.1                             # Low for precision
CALCULATOR_INCLUDE_USAGE=true

# Corrector Subagent Configuration (via LiteLLM)
CORRECTOR_PROVIDER=openrouter                          # openrouter | openai | anthropic
CORRECTOR_MODEL=google/gemini-2.5-flash-preview       # 2025 Best: PT-BR grammar + cost ($0.30/$2.50 per 1M)
# Alternatives:
# - anthropic/claude-3.7-sonnet (Premium: $3/$15)
# - google/gemini-2.0-flash-exp (FREE)
CORRECTOR_MAX_TOKENS=2000
CORRECTOR_TEMPERATURE=0.1                              # Low for consistency
CORRECTOR_INCLUDE_USAGE=true

# Translator Subagent Configuration (via LiteLLM)
TRANSLATOR_PROVIDER=openrouter                         # openrouter | openai | anthropic
TRANSLATOR_MODEL=google/gemini-2.5-pro                # 2025 Best: Multilingual quality ($1.25/$10 per 1M)
# Alternatives:
# - anthropic/claude-3.7-sonnet (Excellent: $3/$15)
# - google/gemini-2.5-flash-preview (Budget: $0.30/$2.50)
# - deepseek/deepseek-chat-v3-0324:free (FREE)
TRANSLATOR_MAX_TOKENS=2000
TRANSLATOR_TEMPERATURE=0.3                             # Moderate for creativity
TRANSLATOR_INCLUDE_USAGE=true

# Weather Subagent Configuration (via LiteLLM)
WEATHER_PROVIDER=openrouter                            # openrouter | openai | anthropic
WEATHER_MODEL=openai/gpt-4.1-nano                     # 2025 Best: Tool calling + low latency ($0.10/$0.40 per 1M)
# Alternatives:
# - google/gemini-2.5-flash-preview (Budget: $0.30/$2.50)
# - openai/gpt-4o-mini (Stable: $0.15/$0.60)
WEATHER_MAX_TOKENS=1500
WEATHER_TEMPERATURE=0.1
WEATHER_INCLUDE_USAGE=true

# ============================================
# VISION AGENT CONFIGURATION (LiteLLM)
# ============================================
# Vision Agent uses OpenAI Agents SDK + LiteLLM Multi-Provider
# Supports 400+ multimodal models via configurable provider

VISION_PROVIDER=openrouter                    # openrouter | openai | anthropic
VISION_MODEL=openai/gpt-4o                    # 2025 Best: Multimodal ($2.50/$10 per 1M)
# Alternatives:
# - anthropic/claude-3.5-sonnet (Claude Vision: $3/$15)
# - google/gemini-2.5-pro (Gemini Vision: $1.25/$10)
VISION_MAX_TOKENS=2000
VISION_TEMPERATURE=0.1
VISION_REASONING_EFFORT=medium                # minimal | low | medium | high
VISION_CACHE_TTL=600                          # Cache TTL in seconds
VISION_INCLUDE_USAGE=true

# Vision Agent Post-processing
ENABLE_VISION_POSTPROCESSING=true

# Conversationalization Model (Optional)
# Model used for converting technical Vision Agent analysis to conversational responses
# Default: gpt-4o-mini (lightweight and cost-effective)
CONVERSATIONALIZATION_MODEL=gpt-4o-mini

# Vision Agent Rate Limiting (MANTIDO)
VISION_RATE_LIMIT_PER_MINUTE=10
VISION_RATE_LIMIT_PER_HOUR=50
VISION_MONTHLY_QUOTA=1000

# Vision Agent Cost Control (MANTIDO)
VISION_MAX_COST_PER_ANALYSIS=0.10
VISION_DAILY_BUDGET_LIMIT=50.00
VISION_MONTHLY_BUDGET_LIMIT=500.00

# Weather API (Optional)
OPENWEATHER_API_KEY=your_openweather_api_key_here

# Supabase Configuration (Optional)
SUPABASE_URL=your_supabase_url_here
SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_KEY=your_supabase_service_key_here
SUPABASE_JWT_SECRET=your_supabase_jwt_secret_here

# JWT Token Configuration
SUPABASE_JWT_EXPIRATION_HOURS=24

# System Configuration
LOG_LEVEL=INFO
ENVIRONMENT=development

# VOXY Logging Configuration
# Controls VOXY system logging level and visual output
# Options: DEBUG | INFO | WARNING | ERROR
VOXY_LOG_LEVEL=INFO              # INFO = Visual limpo (startup sem cabeçalhos), DEBUG = Rastreamento completo
VOXY_ENV=development             # development | production
VOXY_LOG_DIR=logs                # Diretório de logs
VOXY_LOG_JSON=false              # Habilitar JSON sink para ELK/Loki

# Visual Limpo em Startup:
# - VOXY_LOG_LEVEL=INFO: Logs STARTUP aparecem SEM cabeçalho (visual limpo)
# - VOXY_LOG_LEVEL=DEBUG: Logs STARTUP aparecem COM cabeçalho (rastreamento técnico)

# IMPORTANTE: Override Behavior
# O sistema usa load_dotenv(override=True) em todos os módulos de configuração.
# Isso significa que valores neste arquivo .env sempre têm PRIORIDADE sobre
# variáveis de ambiente setadas no shell (via export).
#
# Exemplo:
# - Shell: export VOXY_LOG_LEVEL=INFO
# - .env:  VOXY_LOG_LEVEL=DEBUG
# - Resultado: Sistema usa DEBUG (valor do .env sobrescreve shell)

# LiteLLM Logging Configuration
# Controls LiteLLM's native logging (prevents duplicate logs)
# Options: DEBUG | INFO | WARNING | ERROR
LITELLM_LOG=ERROR                # Recommended: ERROR (only critical issues, avoids duplication)

# ============================================
# UNIVERSAL REASONING/THINKING CONFIGURATION
# ============================================
# Habilita captura avançada de reasoning/thinking de múltiplos provedores LLM
# Suporta: Claude Extended Thinking, Gemini Thinking Config, OpenAI Reasoning Tokens, Grok/DeepSeek reasoning_content

# VOXY Orchestrator - Reasoning Configuration
ORCHESTRATOR_REASONING_ENABLED=true                   # Habilitar captura de reasoning (default: true)
ORCHESTRATOR_THINKING_BUDGET_TOKENS=10000             # Claude Extended Thinking: Budget de tokens (~10K tokens de raciocínio)
ORCHESTRATOR_GEMINI_THINKING_BUDGET=1024              # Gemini Thinking Config: Budget 0-24576, -1=auto (default: 1024)
# ORCHESTRATOR_REASONING_EFFORT já configurado acima (linha 28)

# Vision Agent - Reasoning Configuration
VISION_REASONING_ENABLED=true                         # Habilitar captura de reasoning (default: true)
VISION_THINKING_BUDGET_TOKENS=8000                    # Claude/Anthropic Vision: Budget de tokens para análise
VISION_GEMINI_THINKING_BUDGET=1024                    # Gemini Vision: Budget de thinking
# VISION_REASONING_EFFORT já configurado acima (linha 94)

# Calculator Agent - Reasoning Configuration (Grok suporta reasoning_content automático)
CALCULATOR_REASONING_ENABLED=true                     # Habilitar captura (default: true)

# Corrector Agent - Reasoning Configuration
CORRECTOR_REASONING_ENABLED=false                     # Geralmente desabilitado (default: false)
CORRECTOR_GEMINI_THINKING_BUDGET=512                  # Gemini Flash: Budget reduzido (opcional)

# Translator Agent - Reasoning Configuration
TRANSLATOR_REASONING_ENABLED=false                    # Geralmente desabilitado (default: false)
TRANSLATOR_GEMINI_THINKING_BUDGET=1024                # Gemini Pro: Budget médio (opcional)

# Weather Agent - Reasoning Configuration
WEATHER_REASONING_ENABLED=false                       # Weather não precisa reasoning (default: false)

# ============================================
# OPENROUTER REASONING CONFIGURATION
# ============================================
# OpenRouter usa formato unificado 'reasoning' que funciona para TODOS os modelos
# Aplicável quando *_PROVIDER=openrouter (Orchestrator, Vision, Subagents)
#
# Formato OpenRouter (detectado automaticamente pelo sistema):
#   reasoning = {
#     "enabled": true,
#     "max_tokens": 10000,       # OU
#     "effort": "high"            # high/medium/low
#   }
#
# Conversão Automática (OpenRouter):
#   - ORCHESTRATOR_THINKING_BUDGET_TOKENS=10000 → reasoning.max_tokens=10000
#   - ORCHESTRATOR_REASONING_EFFORT=high → reasoning.effort=high
#   - effort="high" (sem max_tokens) → max_tokens = 80% do ORCHESTRATOR_MAX_TOKENS
#   - effort="medium" → 50% do max_tokens
#   - effort="low" → 20% do max_tokens
#
# IMPORTANTE: OpenRouter converte automaticamente para formato provider-specific:
#   - Anthropic Claude: reasoning → thinking.budget_tokens
#   - Google Gemini: reasoning → thinking_config.thinking_budget
#   - OpenAI GPT-5/o1: reasoning.effort → reasoning_effort
#   - Grok: reasoning_content retornado automaticamente (sem config necessária)
#
# Reasoning já configurado via variáveis acima:
# - ORCHESTRATOR_REASONING_EFFORT=medium (linha 28) → usado por OpenRouter
# - ORCHESTRATOR_THINKING_BUDGET_TOKENS=10000 (linha 162) → reasoning.max_tokens
# - VISION_REASONING_EFFORT=medium (linha 94) → usado por OpenRouter
# - VISION_THINKING_BUDGET_TOKENS=8000 (linha 168) → reasoning.max_tokens

# ============================================
# REASONING CAPTURE - PROVIDER SUPPORT MATRIX
# ============================================
# QUANDO USANDO OPENROUTER (provider=openrouter):
# ✅ Claude Sonnet 4.5:     reasoning.max_tokens → Full thinking blocks + signatures
# ✅ Gemini 2.5:            reasoning.max_tokens → Thought summaries
# ✅ OpenAI GPT-5/o1:       reasoning.effort → Token count + some content
# ✅ Grok Code Fast 1:      reasoning_content automático → Full reasoning text
# ✅ DeepSeek Chat v3.1:    reasoning_content automático → Full reasoning text
#
# QUANDO USANDO PROVIDER DIRETO (provider=anthropic/google/openai):
# ✅ Claude (direto):       thinking.budget_tokens → Full thinking blocks
# ✅ Gemini (direto):       thinking_config.budget → Thought summaries
# ⚠️  OpenAI (direto):      reasoning_effort → Limited content
#
# Sistema Universal detecta automaticamente o provider e usa formato apropriado.
# Ver: src/voxy_agents/config/reasoning_config.py → to_openrouter_params()